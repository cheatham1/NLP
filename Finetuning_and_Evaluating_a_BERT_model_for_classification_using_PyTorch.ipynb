{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cheatham1/NLP/blob/main/Finetuning_and_Evaluating_a_BERT_model_for_classification_using_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FfqM7xWqzBK"
      },
      "source": [
        "## EU-JAV - Finetuning and Evaluating a BERT model for Classification\n",
        "\n",
        "\n",
        "\n",
        "In this notebook we will finetune BERT base models.\n",
        "\n",
        "\n",
        "After training, we will save the model, evaluate it and use it for predictions.\n",
        "\n",
        "\n",
        "Thanks to Per from the National Library of Norway"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Runtime > Change runtime type menu - GPU\n",
        "\n",
        "#gpu_info = !nvidia-smi\n",
        "#if gpu_info.find('failed') >= 0:\n",
        "#gpu_info = '\\n'.join(gpu_info)\n",
        "#  print('Not connected to a GPU')\n",
        "#else:\n",
        "#  print(gpu_info)"
      ],
      "metadata": {
        "id": "JPpwbycUZVt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "3y1t6f-TqKj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JCcC7lE8kCy"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz_FIbsIqfGu"
      },
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate -U\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "from transformers import EarlyStoppingCallback\n",
        "#from transformers import BertForPreTraining\n",
        "#from transformers import RobertaTokenizer, RobertaModel, RobertaForSequenceClassification\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM\n",
        "#from transformers import CamembertModel, CamembertTokenizer\n",
        "#from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "from transformers import RobertaTokenizer, XLMRobertaXLForSequenceClassification\n",
        "\n",
        "#from transformers import ElectraForSequenceClassification\n",
        "#from transformers import XLMTokenizer, XLMWithLMHeadModel\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers\n",
        "\n",
        "#print(transformers.__version__)"
      ],
      "metadata": {
        "id": "PqVH2gJ5jcs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LwbdSXsVCNO"
      },
      "source": [
        "#@markdown Set the main model that the training should start from\n",
        "#\n",
        "#model_name = 'bert-base-multilingual-uncased' #@param [\"NbAiLab/nb-bert-base\", \"NbAiLab/nb-bert-large\", \"bert-base-multilingual-cased\", \"bert-base-multilingual-uncased\"]\n",
        "#model_name = 'm-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0' #@param [\"dbmdz/bert-base-italian-xxl-uncased\", \"dbmdz/bert-base-italian-xxl-cased\",\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\",\"bert-base-multilingual-cased\",\"bert-base-multilingual-uncased\"]\n",
        "#model_name = 'digitalepidemiologylab/covid-twitter-bert-v2'\n",
        "#model_name = 'dbmdz/bert-base-italian-xxl-uncased' #@param [\"dbmdz/bert-base-italian-xxl-uncased\",\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\",\"bert-base-uncased\", \"bert-base-multilingual-cased\"]\n",
        "#model_name = 'xlm-roberta-base' #@param['roberta-base','xlm-roberta-base','roberta-large-mnli','cardiffnlp/twitter-roberta-base', 'dbmdz/bert-base-italian-uncased']\n",
        "\n",
        "\n",
        "#model_name = \"google/electra-small-discriminator\"\n",
        "#model_name = \"dbmdz/electra-base-italian-xxl-cased-discriminator\"\n",
        "model_name = \"xlm-roberta-large\"\n",
        "#model_name = \"xlm-roberta-xlarge\"\n",
        "#model_name = \"xlm-roberta-base\"\n",
        "#odel_name = \"dbmdz/bert-base-italian-xxl-uncased\"\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Set training parameters\n",
        "batch_size =  16 #16@param {type: \"integer\"}\n",
        "learning_rate = 2e-5 #@param {type: \"number\"}\n",
        "warmup_proportion = 0.15 #@param {type: \"number\"}\n",
        "\n",
        "num_epochs = 15 #@param {type: \"integer\"} # 13\n",
        "max_seq_length = 96 #256 , 128, 98, 128@param {type: \"integer\"}\n",
        "weight_decay = 0.01 #@param {type: \"number\"} # 0.01\n",
        "\n",
        "# Electra\n",
        "#tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "#model = ElectraForSequenceClassification.from_pretrained(model_name, num_labels = 3)\n",
        "\n",
        "# BERT\n",
        "#tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "#model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "#model = BertModel.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "# roberta-base\n",
        "#tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "#model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "# xlm-roberta-large and base **\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "#tokenizer = RobertaTokenizer.from_pretrained(\"xlm-roberta-xlarge\")\n",
        "#model = XLMRobertaXLForSequenceClassification.from_pretrained(\"xlm-roberta-xlarge\", problem_type=\"multi_label_classification\")\n",
        "\n",
        "# xlm-roberta-large\n",
        "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#model = AutoModelForMaskedLM.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "#tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
        "#model = CamembertModel.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#model = AutoModel.from_pretrained(model_name)\n",
        "#model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "### finetunig data has 3 or 4 labels 0=promotional,1=neutral,2=discouraging,3=contro-no-vax\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnse7vWrGNVe"
      },
      "source": [
        "removeUserLink = False\n",
        "addData = True  # True = use dataset1+2\n",
        "useUnSplitData = False\n",
        "#useRemovedDifficultTrainingData = False # datset saved after initial run to remove difficult tweets\n",
        "useSpanishData = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = tokenizer.convert_ids_to_tokens(range(tokenizer.vocab_size))\n",
        "print(len(vocab))"
      ],
      "metadata": {
        "id": "nTl3XOvXUILJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"maschera\", \"mask\", \"covid\", \"coronavirus\", \"virus\", \"isolation\", \"confinement\", \"vaccination\", \"vaccine\"]\n",
        "for word in words:\n",
        "  print(word, (word in vocab))"
      ],
      "metadata": {
        "id": "Qfr5Y4-nXDDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(len(tokenizer.vocab))"
      ],
      "metadata": {
        "id": "bl0Q6Mc0Q25w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkHx8JHYWTU6"
      },
      "source": [
        "## Load and Prepare the Dataset used for Finetuning\n",
        "The selected dataset is loaded directly from a web resource. It is coded with labels and text in a comma-separated file. You can replace this with any other data source. This data is here converted into the pytorch data format."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if useUnSplitData:\n",
        "\n",
        "  print(\"Use full datasets and split\")\n",
        "  # ----- Data -----#\n",
        "  data1 = pd.read_csv('https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/no_replies_no_mentions_dataset1_5categories.csv',\n",
        "    names=[\"label\", \"text\"]\n",
        "  )\n",
        "\n",
        "  data2 = pd.read_csv('https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/no_replies_no_mentions_dataset2_5categories.csv',\n",
        "    names=[\"label\", \"text\"]\n",
        "  )\n",
        "\n",
        "  # remove ambiguous\n",
        "  data1.drop( data1[ data1['label'] == 3].index, inplace=True)\n",
        "  data2.drop( data2[ data2['label'] == 3].index, inplace=True)\n",
        "\n",
        "  # remove indiscernable\n",
        "  data1.drop( data1[ data1['label'] == 4].index, inplace=True)\n",
        "  data2.drop( data2[ data2['label'] == 4].index, inplace=True)\n",
        "\n",
        "  #combine indiscernable and neutral\n",
        "  #data1['label'] = data1['label'].replace(4, 1) # indiscernable with neutral\n",
        "  #data2['label'] = data2['label'].replace(4, 1) # indiscernable with neutral\n",
        "\n",
        "  #combine indiscernable and ambiguous\n",
        "  #data1['label'] = data1['label'].replace(4, 3) # indiscernable with neutral\n",
        "  #data2['label'] = data2['label'].replace(4, 3) # indiscernable with neutral\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "\n",
        "  train_data1, devtest_dataset  = train_test_split(data1, train_size=0.6)\n",
        "  dev_data1, test_data1         = train_test_split(devtest_dataset, train_size=0.5)\n",
        "\n",
        "  train_data2, devtest_dataset2  = train_test_split(data2, train_size=0.6)\n",
        "  dev_data2, test_data2       = train_test_split(devtest_dataset2, train_size=0.5)\n",
        "\n",
        "  print(train_data1.shape, dev_data1.shape, test_data1.shape)\n",
        "  print(train_data2.shape, dev_data2.shape, test_data2.shape)"
      ],
      "metadata": {
        "id": "cH7Cwjwt_Oro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data1.groupby(['label']).count()"
      ],
      "metadata": {
        "id": "2SzSXaiAtR_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data2.groupby(['label']).count()"
      ],
      "metadata": {
        "id": "5hsWaYQ8tUU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rdOwBNvBVGa"
      },
      "source": [
        "# ----- Data set 1 Aleady split into train, dev, test-----#\n",
        "\n",
        "train_data1 = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/cheatham1/EU-JAV-AB/main/3categories/datasetA_train_3categories.csv',\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/july_train_3categories_2.csv',\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/dataset1_train_3categories_noreplies_combinedIndiscNeutral.csv',\n",
        "\n",
        "    #names=[\"label\", \"text\"]\n",
        "    names=['Annotator1','Annotator2','Annotator3','label','text clean','index']\n",
        ")\n",
        "dev_data1 = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/cheatham1/EU-JAV-AB/main/3categories/datasetA_dev_3categories.csv',\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/july_dev_3categories_2.csv',\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/dataset1_dev_3categories_noreplies_combinedIndiscNeutral.csv',\n",
        "\n",
        "    #names=[\"label\", \"text\"]\n",
        "    names=['Annotator1','Annotator2','Annotator3','label','text clean','index']\n",
        "\n",
        ")\n",
        "test_data1 = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/cheatham1/EU-JAV-AB/main/3categories/datasetA_test_3categories.csv',\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/july_test_3categories_2.csv',\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/dataset1_test_3categories_noreplies_combinedIndiscNeutral.csv',\n",
        "\n",
        "    #names=[\"label\", \"text\"]\n",
        "    names=['Annotator1','Annotator2','Annotator3','label','text clean','index']\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Dataset1: \", train_data1.shape, dev_data1.shape, test_data1.shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- Data set 2 Aleady split into train, dev, test-----#\n",
        "\n",
        "train_data2 = pd.read_csv(\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/newconsistent_oct21_train_3categories.csv',\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/newconsistent_oct_570_train_3categories.csv',\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/norepeats_oct_train_3categories_2.csv',\n",
        "    #####'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/no_replies_no_mentions_oct_train_3categories_2.csv',\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/dataset2_train_3categories_noreplies_combinedIndiscNeutral.csv',\n",
        "    #names=[\"label\", \"text\"]\n",
        "\n",
        "    'https://raw.githubusercontent.com/cheatham1/EU-JAV-AB/main/3categories/datasetB_train_3categories.csv',\n",
        "    names=['Annotator1','Annotator2','Annotator3','label','text clean','index']\n",
        "    )\n",
        "\n",
        "\n",
        "dev_data2 = pd.read_csv(\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/newconsistent_oct21_dev_3categories.csv',\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/newconsistent_oct_570_dev_3categories.csv',\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/norepeats_oct_dev_3categories_2.csv',\n",
        "    #####'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/no_replies_no_mentions_oct_dev_3categories_2.csv',\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/dataset2_dev_3categories_noreplies_combinedIndiscNeutral.csv',\n",
        "\n",
        "    #names=[\"label\", \"text\"]\n",
        "    'https://raw.githubusercontent.com/cheatham1/EU-JAV-AB/main/3categories/datasetB_dev_3categories.csv',\n",
        "    names=['Annotator1','Annotator2','Annotator3','label','text clean','index']\n",
        ")\n",
        "\n",
        "\n",
        "test_data2 = pd.read_csv(\n",
        "    #'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/no_replies_no_mentions_oct_test_3categories_2.csv',\n",
        "    #names=[\"label\", \"text\"]\n",
        "\n",
        "    'https://raw.githubusercontent.com/cheatham1/EU-JAV-AB/main/3categories/datasetB_test_3categories.csv',\n",
        "    names=['Annotator1','Annotator2','Annotator3','label','text clean','index']\n",
        ")\n",
        "\n",
        "print(\"Dataset2: \", train_data2.shape, dev_data2.shape, test_data2.shape)\n"
      ],
      "metadata": {
        "id": "Sm7E8S1vw-FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Relabelled dev data\n",
        "\n",
        "dev_data1_r = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/cheatham1/EU-JAV-AB/main/3categories/DevDataA_DisagreeLabelsAndPredictions_relabeled.csv\",\n",
        "    names=[\"text clean\",\"label\",\"index\"], skiprows = 1\n",
        ")\n",
        "\n",
        "dev_data2_r = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/cheatham1/EU-JAV-AB/main/3categories/DevDataB_DisagreeLabelsAndPredictions_relabeled.csv\",\n",
        "    names=[\"text clean\",\"label\",\"index\"], skiprows = 1\n",
        ")\n",
        "print(\"Dataset relabelled: \", dev_data1_r.shape, dev_data2_r.shape)\n"
      ],
      "metadata": {
        "id": "ROS0NfIU55D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_data1_r.groupby(['label']).count()"
      ],
      "metadata": {
        "id": "Pg9BP0BXqN1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_data2_r.groupby(['label']).count()"
      ],
      "metadata": {
        "id": "VlYEl6PuqTu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_data1_r.head()"
      ],
      "metadata": {
        "id": "OXBCcds-9Elr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN6pZAPiiq24"
      },
      "source": [
        "if addData == True:\n",
        "  print(\"adding datasets\")\n",
        "\n",
        "  train_data = train_data1.append(train_data2)\n",
        "  dev_data  = dev_data1.append(dev_data2)\n",
        "  test_data  = test_data1.append(test_data2)\n",
        "\n",
        "else:\n",
        "  train_data= train_data1.copy()\n",
        "  dev_data= dev_data1.copy()\n",
        "  test_data= test_data1.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use relabelled dev data\n",
        "# dev_data  = dev_data1_r.append(dev_data2_r)\n"
      ],
      "metadata": {
        "id": "n5ZJwW7w9rZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_spanish = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/train_spanish_dataset.csv',\n",
        "    names=[\"label\", \"text\"])\n",
        "\n",
        "dev_data_spanish = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/dev_spanish_dataset.csv',\n",
        "    names=[\"label\", \"text\"])\n"
      ],
      "metadata": {
        "id": "Q49kftPNLAJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.groupby(['label']).count()"
      ],
      "metadata": {
        "id": "8GFdOVC2wRh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if useSpanishData:\n",
        "  train_data = train_data.append(train_data_spanish)\n",
        "  dev_data = dev_data.append(dev_data_spanish)"
      ],
      "metadata": {
        "id": "DvnpEuFNNdA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if useRemovedDifficultTrainingData == True:\n",
        "#  test_data = pd.read_csv(\n",
        "#      'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/trainingDataReduced_10epochs_1007.csv',\n",
        "#      names=[\"label\", \"text\"])\n"
      ],
      "metadata": {
        "id": "JG--gZwA5ew8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install emoji\n",
        "#import emoji\n",
        "#train_data['text'] = train_data['text'].apply(lambda x: emoji.demojize(x))\n",
        "#dev_data['text']   = dev_data['text'].apply(lambda x: emoji.demojize(x))\n",
        "#test_data['text']  = test_data['text'].apply(lambda x: emoji.demojize(x))"
      ],
      "metadata": {
        "id": "su5XCoO6ztXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K73F7jdKJAwP"
      },
      "source": [
        "train_data.groupby(['label']).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6SbWl-4J9i0"
      },
      "source": [
        "dev_data.groupby(['label']).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOIPkZkmnK8l"
      },
      "source": [
        "print(f'The dataset is imported.\\n\\nThe training dataset has {len(train_data)} items.\\nThe development dataset has {len(dev_data)} items. \\nThe test dataset has {len(test_data)} items')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H92Asgy_Hdz"
      },
      "source": [
        "train_data.label = train_data.label.astype('float').astype('Int64')\n",
        "dev_data.label = dev_data.label.astype('float').astype('Int64')\n",
        "test_data.label = test_data.label.astype('float').astype('Int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_dev = list(dev_data[\"text\"])\n",
        "#X_test = list(test_data[\"text\"])\n",
        "\n",
        "#X_dev_tokenized = tokenizer(X_dev, padding=True, truncation=True, max_length=120)\n",
        "#X_test_tokenized = tokenizer(X_dev, padding=True, truncation=True, max_length=120)\n"
      ],
      "metadata": {
        "id": "iVao3CilZIBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvwMibpe1NEC"
      },
      "source": [
        "#def removeUserLink(df):\n",
        "#  df['text clean'] = df.text.str.replace('user','')\n",
        "#  df['text clean'] = df.text.str.replace('link','')\n",
        "#  return(df)\n",
        "\n",
        "#if removeUserLink:\n",
        "#  dev_data = removeUserLink(dev_data)\n",
        "##  train_data = removeUserLink(train_data)\n",
        "#  test_data = removeUserLink(test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data['text'] = train_data.text.str.replace('\\n',' ')\n",
        "#dev_data['text'] = dev_data.text.str.replace('\\n',' ')\n",
        "#test_data['text'] = test_data.text.str.replace('\\n',' ')"
      ],
      "metadata": {
        "id": "d23fXvyuMMbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te38-MEeA-2_"
      },
      "source": [
        "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
        "dev_data = dev_data.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3Ik6H_eMgbi"
      },
      "source": [
        "## ----- Preprocess data -----#\n",
        "\n",
        "X_train = list(train_data[\"text clean\"])\n",
        "y_train = list(train_data[\"label\"])\n",
        "X_val = list(dev_data[\"text clean\"])\n",
        "y_val = list(dev_data[\"label\"])\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=max_seq_length)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=max_seq_length)\n",
        "\n",
        "# Create torch dataset\n",
        "\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)\n",
        "\n",
        "print(f'The dataset is imported.\\n\\nThe training dataset has {len(train_data)} items.\\nThe development dataset has {len(dev_data)} items. \\nThe test dataset has {len(test_data)} items')\n",
        "steps = round(len(train_data)/batch_size)\n",
        "\n",
        "num_warmup_steps = round(steps*warmup_proportion*num_epochs)\n",
        "print(f'You are planning to train for a total of {steps} steps * {num_epochs} epochs = {num_epochs*steps} steps. Warmup is {num_warmup_steps} steps or {round(100*num_warmup_steps/(steps*num_epochs))}%. We recommend at least 10%.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7WNLD_jP3OI"
      },
      "source": [
        "totalsize = len(train_data) + len(dev_data) + len(test_data)\n",
        "print(f'The dataset total size {totalsize}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train[0]"
      ],
      "metadata": {
        "id": "jVC0QfN9JEQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sample = \"coronavirus: vaccino usa, il professor bucci sulla sperimentazione di moderna\"\n",
        "#sample = \"coronavirus: modern testingâ€\n",
        "#sample= \"https://t.co/Ub5NJddOYm\"\n",
        "#sample = \"https://t.co/YfZ7jhi1mN\"\n",
        "\n",
        "#print(encoding)\n",
        "##encoding = tokenizer.encode(sample)\n",
        "#print(tokenizer.convert_ids_to_tokens(encoding))\n"
      ],
      "metadata": {
        "id": "aEoR01OO_pyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYVyn0Q3W1sg"
      },
      "source": [
        "# Start Training\n",
        "We are here using the HuggingFace Trainer interface. An alternative implementation could be to use Tensorflow/Keras or native PyTorch.\n",
        "\n",
        "Please note that training the large BERT-model on a GPU might be a challenge. The two critical parameters are batch_size and sequence_length. Reduce these until you no longer are getting Out-of-memory(OOM) errors. The political speeches corpus above have very long sequences. You might want to truncate them at 128 tokens. This makes the task harder since the model is allowed to see less of each sequence. Reducing batch_size below 8 might lead to unstability and very long training time."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.optimization import Adafactor, AdafactorSchedule\n",
        "\n",
        "optimizer = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
        "lr_scheduler = AdafactorSchedule(optimizer)"
      ],
      "metadata": {
        "id": "oBHEtQ_npkHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKM8Elz-Uw95"
      },
      "source": [
        "# ----- Fine-tune pretrained model -----#\n",
        "# Define Trainer parameters\n",
        "def compute_metrics(p):\n",
        "    pred, label = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=label, y_pred=pred)\n",
        "   # recall = recall_score(y_true=labels, y_pred=pred)\n",
        "   # precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    #accuracy = f1_score(y_true=label, y_pred=pred)\n",
        "\n",
        "    recall = recall_score(y_true=label, y_pred=pred, average='weighted')\n",
        "    precision = precision_score(y_true=label, y_pred=pred, average='weighted')\n",
        "    f1 = f1_score(y_true=label, y_pred=pred, average='weighted')\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "# Define Trainer\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    #evaluation_strategy=\"steps\",\n",
        "    #eval_steps=round(steps/2),\n",
        "    #logging_steps=round(steps/10),\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    learning_rate=learning_rate, #The default here is linear decay to 0.\n",
        "    warmup_steps=num_warmup_steps,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay = weight_decay,\n",
        "    #save_steps=steps, #Only saves at the end\n",
        "    seed= 13, #3,\n",
        "    metric_for_best_model= \"accuracy\",\n",
        "    load_best_model_at_end=True,\n",
        "    #push_to_hub=True,\n",
        "    #push_to_hub_model_id=f\"{model_name}-finetuned-EUJAV\",\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    #optimizers=(optimizer, lr_scheduler),  ##### do we want this?\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "    #callbacks = [tboard_callback]\n",
        ")\n",
        "\n",
        "\n",
        "# Train pre-trained model\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow as tf\n",
        "#import datetime\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "#rm -rf ./logs/"
      ],
      "metadata": {
        "id": "o25_HTCA0RpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#less output/checkpoint-490/trainer_state.json"
      ],
      "metadata": {
        "id": "JbFRpl34Kopf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "#files.download('output/checkpoint-392/trainer_state.json')\n"
      ],
      "metadata": {
        "id": "GEKUwSyK29Pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape, dev_data.shape, test_data.shape)"
      ],
      "metadata": {
        "id": "xrIt6jj48CM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(model)"
      ],
      "metadata": {
        "id": "aYiVRdsw_Moe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_m5laKFlsNs"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#:: reinstate early stopping"
      ],
      "metadata": {
        "id": "3gmzLE9HxoMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE4sY-cpXUEF"
      },
      "source": [
        "# Run Preditions and print Evaluation Report\n",
        "The code below first runs predictions on the train dataset. After that it prints and evaluation report using a tool from sklearn.\n",
        "\n",
        "Typically it is two number you want from this: The accuracy score (the first number on the \"accuracy\"-line. In addtion most journals want you to report the F1-macro-score since this is a sequence classification task. This is the number beneath accuracy (or in the intersection between f1-score and macro-avg).\n",
        "\n",
        "One of the tasks above is a balanced dataset. Both are binary classification. In a balanced binary classification the F1-macro and the average is basically the same (rounding differences only). In the unbalanced set, these values will vary greatly. The F1-macro is typically a much better measurement of how good your network is doing.\n",
        "\n",
        "We repeat the same raport for eval and test as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItbQEO1OUdHj"
      },
      "source": [
        "#Print report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "print(\"\\nTest-set Evaluation\")\n",
        "X_test = list(test_data[\"text clean\"])\n",
        "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=max_seq_length)\n",
        "test_dataset = Dataset(X_test_tokenized)\n",
        "raw_pred, _, _ = trainer.predict(test_dataset)\n",
        "y_pred_bool_test = np.argmax(raw_pred, axis=1)\n",
        "#print(classification_report(test_data[\"label\"], y_pred_bool, digits=3))\n",
        "print(classification_report(test_data[\"label\"].to_numpy().astype(\"int\"), y_pred_bool_test, digits=3))\n",
        "\n",
        "#print(classification_report(X_test[\"label\"], y_pred_bool, digits=4))\n",
        "\n",
        "print(\"\\nValidation-set Evaluation\")\n",
        "dev_dataset = Dataset(X_val_tokenized)\n",
        "w_pred, _, _ = trainer.predict(dev_dataset)\n",
        "y_pred_bool_dev = np.argmax(w_pred, axis=1)\n",
        "#print(classification_report(dev_data[\"label\"], y_pred_bool, digits=3))\n",
        "print(classification_report(dev_data[\"label\"].to_numpy().astype(\"int\"), y_pred_bool_dev, digits=3))\n",
        "\n",
        "\n",
        "print(\"\\nTrain-set Evaluation\")\n",
        "train_dataset = Dataset(X_train_tokenized)\n",
        "train_pred, _, _ = trainer.predict(train_dataset)\n",
        "y_pred_bool_train = np.argmax(train_pred, axis=1)\n",
        "#print(classification_report(train_data[\"label\"], y_pred_bool, digits=3))\n",
        "print(classification_report(train_data[\"label\"].to_numpy().astype(\"int\"), y_pred_bool_train, digits=3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label_prediction = train_data.copy()\n",
        "\n",
        "df_label_prediction['prediction'] = y_pred_bool_train.tolist()"
      ],
      "metadata": {
        "id": "5BVK30f_xCal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label_prediction.head()"
      ],
      "metadata": {
        "id": "jc2blTBAvUxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label_prediction.shape"
      ],
      "metadata": {
        "id": "g5ckbMrb1B1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_bool_train.shape"
      ],
      "metadata": {
        "id": "Mu736DU91kYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "id": "ztJWMzuA1QzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "df_label_prediction.to_csv('trainingDataLabelsPredictions.csv')\n",
        "files.download('trainingDataLabelsPredictions.csv')"
      ],
      "metadata": {
        "id": "2zvEApHXyB2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove difficult to label data from training dataset\n",
        "#indexNames = df_label_prediction[ df_label_prediction['label'] != df_label_prediction['prediction'] ].index\n",
        "\n",
        "# Remove easy to label data from training dataset\n",
        "#indexNames = df_label_prediction[ df_label_prediction['label'] == df_label_prediction['prediction'] ].index\n",
        "\n",
        "#df_label_prediction.drop(indexNames , inplace=True)\n",
        "#size=df_label_prediction.shape[0]\n",
        "#orig_size = train_data.shape[0]\n",
        "#print(size, (orig_size-size)/orig_size)"
      ],
      "metadata": {
        "id": "OrKxHpoG2mwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_label_prediction.head()"
      ],
      "metadata": {
        "id": "VQID2k7Qg7dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess reduced training dataset\n",
        "X_train_r = list(df_label_prediction[\"text clean\"])\n",
        "y_train_r = list(df_label_prediction[\"label\"])\n",
        "\n",
        "X_train_r_tokenized = tokenizer(X_train_r, padding=True, truncation=True, max_length=max_seq_length)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=max_seq_length)\n",
        "\n",
        "train_r_dataset = Dataset(X_train_r_tokenized, y_train_r)"
      ],
      "metadata": {
        "id": "caYamYs12m5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"output2\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    #evaluation_strategy=\"steps\",\n",
        "    #eval_steps=round(steps/2),\n",
        "    #logging_steps=round(steps/10),\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    learning_rate=learning_rate, #The default here is linear decay to 0.\n",
        "    warmup_steps=num_warmup_steps,\n",
        "    num_train_epochs=11,\n",
        "    weight_decay = weight_decay,\n",
        "    #save_steps=steps, #Only saves at the end\n",
        "    ######seed=0,\n",
        "    metric_for_best_model= \"accuracy\",\n",
        "    load_best_model_at_end=True,\n",
        "    #push_to_hub=True,\n",
        "    #push_to_hub_model_id=f\"{model_name}-finetuned-EUJAV\",\n",
        ")"
      ],
      "metadata": {
        "id": "28-hj3R5V0H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2 = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_r_dataset, # reduced dataset. Difficult tweets removed\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer, lr_scheduler),  ##### do we want this?\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n",
        "# Train again on reduced training dataset\n",
        "trainer2.train()"
      ],
      "metadata": {
        "id": "h96mYM9xpitv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#files.download('output2/checkpoint-94/trainer_state.json')"
      ],
      "metadata": {
        "id": "MolDb9qDyXlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#less output2/checkpoint-260/trainer_state.json"
      ],
      "metadata": {
        "id": "BfEOOfqNC6Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nReduced Training-set (difficult tweets removed) Evaluation ******\")\n",
        "print(\"\\nTest-set Evaluation\")\n",
        "raw_pred2, _, _ = trainer2.predict(test_dataset)\n",
        "y_pred_bool_test2 = np.argmax(raw_pred2, axis=1)\n",
        "print(classification_report(test_data[\"label\"].to_numpy().astype(\"int\"), y_pred_bool_test2, digits=3))\n",
        "\n",
        "print(\"\\nValidation-set Evaluation\")\n",
        "w_pred2, _, _ = trainer2.predict(dev_dataset)\n",
        "y_pred_bool_dev2 = np.argmax(w_pred2, axis=1)\n",
        "print(classification_report(dev_data[\"label\"].to_numpy().astype(\"int\"), y_pred_bool_dev2, digits=3))\n",
        "\n",
        "\n",
        "print(\"\\nTrain-set Evaluation: evaluate on reduced training dataset\")\n",
        "train_pred2, _, _ = trainer2.predict(train_r_dataset)\n",
        "y_pred_bool_train2 = np.argmax(train_pred2, axis=1)\n",
        "print(classification_report(df_label_prediction[\"label\"].to_numpy().astype(\"int\"), y_pred_bool_train2, digits=3))\n"
      ],
      "metadata": {
        "id": "tm_A-b8IDacd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPuh8Y8z1wFX"
      },
      "source": [
        "**Confusion** matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-F4LZtGK-JW"
      },
      "source": [
        "from matplotlib import rcParams\n",
        "rcParams['figure.figsize'] = 8, 8\n",
        "font_size = 22"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMoNCuvm1t77"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#y_test = test_data[\"label\"]\n",
        "y_test = test_data[\"label\"].to_numpy().astype(\"int\")\n",
        "y_pred_test = np.argmax(raw_pred2, axis=1)\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "cnf_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySQApnsc5HxL"
      },
      "source": [
        "test_data_results = test_data.copy()\n",
        "test_data_results['orig label'] = y_test\n",
        "test_data_results['pred label'] = y_pred_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBSGJAAJ40o_"
      },
      "source": [
        "test_data_results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c40kUba-8AbU"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IClEQ65515d"
      },
      "source": [
        "test_labels_agree_df = test_data_results[test_data_results['orig label'] == test_data_results['pred label']]\n",
        "test_labels_not_agree_df = test_data_results[test_data_results['orig label'] != test_data_results['pred label']]\n",
        "\n",
        "print(test_labels_agree_df.shape[0], test_labels_not_agree_df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW72PASF51-R"
      },
      "source": [
        "#test_labels_not_agree_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCkCNWhz07H6"
      },
      "source": [
        "counts = np.unique(y_pred_test, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkTxnFiE6qvq"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_full_data = f1_score(y_test, y_pred_test, average='macro')\n",
        "f1_full_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "acc_full_data = accuracy_score(y_test, y_pred_test)\n",
        "acc_full_data"
      ],
      "metadata": {
        "id": "eldhzKrBeovf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9i0qKRcXt7g"
      },
      "source": [
        "# Test with dataset1. Trainer 2\n",
        "test_data = test_data1.copy()\n",
        "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "X_test = list(test_data[\"text clean\"])\n",
        "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=max_seq_length)\n",
        "\n",
        "test_dataset = Dataset(X_test_tokenized)\n",
        "raw_pred, _, _ = trainer2.predict(test_dataset)\n",
        "y_pred_test = np.argmax(raw_pred, axis=1)\n",
        "y_test = test_data[\"label\"].to_numpy().astype(\"int\")\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred_test, digits=3))\n",
        "\n",
        "f1_dataset1 = f1_score(y_test, y_pred_test, average='macro')\n",
        "acc_dataset1 = accuracy_score(y_test, y_pred_test)\n",
        "f1_dataset1\n",
        "\n",
        "cnf_matrix_1 = confusion_matrix(y_test, y_pred_test)\n",
        "cnf_matrix_1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkkdinxX619K"
      },
      "source": [
        "### TEST WITH dataset 2 Trainer 2\n",
        "test_data= test_data2.copy()\n",
        "\n",
        "X_test = list(test_data[\"text clean\"])\n",
        "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=max_seq_length)\n",
        "\n",
        "test_dataset = Dataset(X_test_tokenized)\n",
        "raw_pred, _, _ = trainer2.predict(test_dataset)\n",
        "y_pred_test = np.argmax(raw_pred, axis=1)\n",
        "y_test = test_data[\"label\"].to_numpy().astype(\"int\")\n",
        "\n",
        "print(classification_report(y_test, y_pred_test, digits=3))\n",
        "\n",
        "f1_dataset2 = f1_score(y_test, y_pred_test, average='macro')\n",
        "acc_dataset2 = accuracy_score(y_test, y_pred_test)\n",
        "f1_dataset2\n",
        "\n",
        "cnf_matrix_2 = confusion_matrix(y_test, y_pred_test)\n",
        "cnf_matrix_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with dataset1+2 Trainer 2\n",
        "test_data= test_data1.copy()\n",
        "test_data = test_data.append(test_data2)\n",
        "\n",
        "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "X_test = list(test_data[\"text clean\"])\n",
        "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=max_seq_length)\n",
        "\n",
        "test_dataset = Dataset(X_test_tokenized)\n",
        "raw_pred, _, _ = trainer2.predict(test_dataset)\n",
        "y_pred_test = np.argmax(raw_pred, axis=1)\n",
        "y_test = test_data[\"label\"].to_numpy().astype(\"int\")\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred_test, digits=3))\n",
        "\n",
        "f1_dataset12 = f1_score(y_test, y_pred_test, average='macro')\n",
        "acc_dataset12 = accuracy_score(y_test, y_pred_test)\n",
        "f1_dataset12\n",
        "\n",
        "cnf_matrix_12 = confusion_matrix(y_test, y_pred_test)\n",
        "cnf_matrix_12"
      ],
      "metadata": {
        "id": "WV6foF35D9hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9kFnFe06vw_"
      },
      "source": [
        "### TEST WITH SPANISH DATA\n",
        "\n",
        "test_data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/newconsistent_Spanish175_PromotionalNeutralDicouraging.csv\",\n",
        "    names=[\"label\", \"text\"])\n",
        "\n",
        "if useSpanishData:\n",
        "  test_data = pd.read_csv(\n",
        "      'https://raw.githubusercontent.com/cheatham1/EU-JAV-DATA/main/test_spanish_dataset.csv',\n",
        "      names=[\"label\", \"text\"])\n",
        "\n",
        "\n",
        "test_data.label = test_data.label.astype('float').astype('Int64')\n",
        "#test_data['text']  = test_data['text'].apply(lambda x: emoji.demojize(x))\n",
        "\n",
        "print(test_data.shape)\n",
        "\n",
        "X_test = list(test_data[\"text\"])\n",
        "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=max_seq_length)\n",
        "\n",
        "test_dataset = Dataset(X_test_tokenized)\n",
        "raw_pred, _, _ = trainer2.predict(test_dataset)\n",
        "\n",
        "y_pred_test = np.argmax(raw_pred, axis=1)\n",
        "y_test = test_data[\"label\"].to_numpy().astype(\"int\")\n",
        "\n",
        "#print(classification_report(test_data[\"label\"].to_numpy().astype(\"int\"), y_pred_test, digits=3))\n",
        "print(classification_report(y_test, y_pred_test, digits=3))\n",
        "\n",
        "f1_spanish_data = f1_score(y_test, y_pred_test, average='macro')\n",
        "acc_spanish_data = accuracy_score(y_test, y_pred_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE2cmrPz61_W"
      },
      "source": [
        "print(\"Results from TEST dataset\")\n",
        "print(\"Accuracy: \")\n",
        "print(\"Full test data: {:.3f}\".format(acc_dataset12))\n",
        "print(\"Dataset1: {:.3f}\".format( acc_dataset1))\n",
        "print(\"Dataset2: {:.3f}\".format( acc_dataset2))\n",
        "print(\"Spanish data: {:.3f}\".format( acc_spanish_data))\n",
        "\n",
        "\n",
        "print(\"F1\")\n",
        "\n",
        "print(\"Full test data: {:.3f}\".format(f1_dataset12))\n",
        "print(\"Dataset1: {:.3f}\".format( f1_dataset1))\n",
        "print(\"Dataset2: {:.3f}\".format( f1_dataset2))\n",
        "print(\"Spanish data: {:.3f}\".format( f1_spanish_data))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        #print(\"Normalized confusion matrix\")\n",
        "\n",
        "    print(cm)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar(shrink=0.7)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    #plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.xticks(tick_marks, classes)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\",\n",
        "                 fontsize=font_size)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label',fontsize=font_size)\n",
        "    plt.xlabel('Predicted label',fontsize=font_size)"
      ],
      "metadata": {
        "id": "_mELC2OCpEkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8hAp6I43yot"
      },
      "source": [
        "import itertools\n",
        "#plt.figure()\n",
        "#class_names= [\"Promotional\",\"Neutral\",\"Discouraging\",\"Ambiguous\",\"Indiscernable\"]\n",
        "\n",
        "class_names= [\"Promotional\",\"Neutral\",\"Discouraging\"]\n",
        "\n",
        "plot_confusion_matrix(cnf_matrix, classes= class_names, normalize=True)\n",
        "plt.title('Normalized Confusion Matrix',fontsize=font_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_matrix"
      ],
      "metadata": {
        "id": "DWy9lqCt1Yny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(cnf_matrix_1, classes= class_names, normalize=True)\n",
        "plt.title('Normalized Confusion Matrix: Test dataset1',fontsize=font_size)\n"
      ],
      "metadata": {
        "id": "EIjRq2L2zJfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(cnf_matrix_2, classes= class_names, normalize=True)\n",
        "plt.title('Normalized Confusion Matrix: Test dataset2',fontsize=font_size)\n"
      ],
      "metadata": {
        "id": "Cn-J9jTAzJmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(cnf_matrix_12, classes= class_names, normalize=True)\n",
        "plt.title('Normalized Confusion Matrix: Test dataset1+2',fontsize=font_size)\n"
      ],
      "metadata": {
        "id": "cKTOGjlKzJoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtDMgHq2Uzqv"
      },
      "source": [
        "# Tokemizer\n",
        "#tokenizer.tokenize(\"#no-vax #novax\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train_tokenized"
      ],
      "metadata": {
        "id": "nslLnf89Elfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!ls output/checkpoint-1/"
      ],
      "metadata": {
        "id": "-ULGJtS_EkFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn1wn49WYiZ2"
      },
      "source": [
        "# **Save the model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "::"
      ],
      "metadata": {
        "id": "sH_6-OZPcaFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr4BypZRZOQL"
      },
      "source": [
        "### THIS NEEDS TO BE RUN to save model\n",
        "### Install git lfs\n",
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
        "!sudo apt-get install git-lfs\n",
        "!git lfs install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDyQQVmsGRFj"
      },
      "source": [
        "# save on huggingface"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM8Cqcafj94J"
      },
      "source": [
        "!git config --global user.email \"Susancheatham1@gmail.com\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sGmnB33TAqr"
      },
      "source": [
        "!huggingface-cli login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "sQBsYl65oONb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uf-xroNXvf7"
      },
      "source": [
        "model_name_to_save = \"xlm-roberta-large-finetuned-d1r01\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPC6HsqtapSa"
      },
      "source": [
        "# Save locally first\n",
        "model.save_pretrained('./xlm-roberta-large-finetuned-d1r01/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE_bInQga1dM"
      },
      "source": [
        "tokenizer.save_pretrained('./xlm-roberta-large-finetuned-d1r01/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m0DBQgxs22g"
      },
      "source": [
        "trainer.save_model('./xlm-roberta-large-finetuned-d1r01/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agraW5QkbzLq"
      },
      "source": [
        "!ls xlm-roberta-large-finetuned-r993/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TDsw0uaxMxl"
      },
      "source": [
        "    # Files to expect...\n",
        "    # a config.json file, which saves the configuration of your model ;\n",
        "    # a pytorch_model.bin file, which is the PyTorch checkpoint (unless you canâ€™t have it for some reason) ;\n",
        "    # a tf_model.h5 file, which is the TensorFlow checkpoint (unless you canâ€™t have it for some reason) ;\n",
        "    # a special_tokens_map.json, which is part of your tokenizer save;\n",
        "    # a tokenizer_config.json, which is part of your tokenizer save;\n",
        "    # files named vocab.json, vocab.txt, merges.txt, or similar, which contain the vocabulary of your tokenizer, part of your tokenizer save;\n",
        "    # maybe a added_tokens.json, which is part of your tokenizer save.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxBkTroZcYKG"
      },
      "source": [
        "!huggingface-cli repo create \"xlm-roberta-large-finetuned-d1r01\" --yes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u8tZh-_uhB_"
      },
      "source": [
        "model.push_to_hub('https://huggingface.co/Cheatham/xlm-roberta-large-finetuned-d1r01/')\n",
        "tokenizer.push_to_hub('https://huggingface.co/Cheatham/xlm-roberta-large-finetuned-d1r01/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxI0S8o2F0dZ"
      },
      "source": [
        "#####import os\n",
        "#### Mount Google Drive to this Notebook instance.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls drive/MyDrive/EU-JAV/Models"
      ],
      "metadata": {
        "id": "g__G28Q18cqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mB9UvjfIE6-"
      },
      "source": [
        "cd MyDrive/EU-JAV/Models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1NHiBE-i-pB"
      },
      "source": [
        "trainer.save_model(\"EU-JAV-finetuned-xlmroberta\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p5iSBHEzL1h"
      },
      "source": [
        "#tokenizer.save_pretrained(\"EU-JAV-finetuned-xlmroberta-tokenizer\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynXYyejJzN00"
      },
      "source": [
        "#model.save_pretrained(\"EU-JAV-finetuned-xlmroberta-model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5XcSUMx4gvH"
      },
      "source": [
        "###drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZNiNBqF3P2u"
      },
      "source": [
        "#ls EU-JAV-models/EUJAV-tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0J-0Xqn3eZq"
      },
      "source": [
        "#ls EU-JAV-models/EUJAV-finetuned-roberta-model_uncased"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6zBdjuq1Tj1"
      },
      "source": [
        "#!git lfs install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "EcsmO9nNEXSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pD2XSEieE0z"
      },
      "source": [
        "\n",
        "model.save_pretrained('https://huggingface.co/Cheatham/xlm-roberta-large-finetuned4/')\n",
        "trainer.save_model('https://huggingface.co/Cheatham/xlm-roberta-large-finetuned4/')\n",
        "tokenizer.save_pretrained('https://huggingface.co/Cheatham/xlm-roberta-large-finetuned4/')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK-vWBW2sxdw"
      },
      "source": [
        "!git config --global user.email susancheatham1@gmail.com"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O63fUD5k6KI9"
      },
      "source": [
        "model.save_pretrained('https://github.com/cheatham1/EU-JAV-Models/xlm-roberta-large-finetuned4')\n",
        "trainer.save_model(\"https://github.com/cheatham1/EU-JAV-Models/xlm-roberta-large-finetuned4\")\n",
        "tokenizer.save_pretrained(\"https://github.com/cheatham1/EU-JAV-Models/xlm-roberta-large-finetuned4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psI8CBB4vMc3"
      },
      "source": [
        "!git init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a44xKVAmo8UZ"
      },
      "source": [
        "!git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOfKqLYEwiAt"
      },
      "source": [
        "!git add xlm-roberta-large-finetuned4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iES0faWoplH8"
      },
      "source": [
        "#\n",
        "!git status\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKp1OC013-dy"
      },
      "source": [
        "!git commit -m \"EU-JAV model update\"\n",
        "!git push"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push --set-upstream origin main"
      ],
      "metadata": {
        "id": "MgtCgEyhzu9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9iaUgmZ4WlR"
      },
      "source": [
        "!git remote add origin https://github.com/cheatham1/EU-JAV-Models.git\n",
        "!git branch -M main\n",
        "!git push -u origin main"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYsB8z3Ntvw0"
      },
      "source": [
        "!git remote set-url origin git@github.com:cheatham1/EU-JAV-Models.git"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}